<!DOCTYPE html>
<html lang="en">
<html>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Iterative Handin</title>
        <link rel="stylesheet" href="styles.css" /> 
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    </head>
    <body>
        <nav>
            <ul class = "topnav">
                <li><a href="https://partiful.com/">Partiful</a></li>
                <li><a href="https://www.figma.com/file/PxpPT6LunJKscrRHJoAKVW/Final-Partiful-Profiles?type=design&node-id=68%3A2197&mode=design&t=ZZASMBRMaU53dpkp-1">Figma</a></li>
                <li class="titleText"><a class="titleText"href="#home">Iterative Handin: Partiful</a></li>
            </ul>
        </nav>
        <div class = "mainText">
            <h1>Partiful Profiles</h1>
            <h2>Introduction</h2>
            <p>We started the process with 32 rough sketches; ideating on 8 different 4 screen flows. 
            </p>
            
  <!-- Slideshow container -->
<div class="slideshow-container">

  <!-- Full-width images with number and caption text -->
  <div class="mySlides fade">
    <img class="slideImg"src="assets/sketch4.png">
  </div>

  <div class="mySlides fade">
    <img class="slideImg" src="assets/sketch1.png" >
  </div>

  <div class="mySlides fade">
    <img class="slideImg" src="assets/sketch2.png" >
  </div>
  <div class="mySlides fade">
    <img  class="slideImg" src="assets/sketch3.png" >
  </div>
  <div class="mySlides fade">
    <img class="slideImg" src="assets/sketch5.png" >
  </div>
  <div class="mySlides fade">
    <img  class="slideImg" src="assets/sketch6.png" >
  </div>

  <!-- Next and previous buttons -->
  <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
  <a class="next" onclick="plusSlides(1)">&#10095;</a>
</div>
<br>

<!-- The dots/circles -->
<div style="text-align:center">
  <span class="dot" onclick="currentSlide(1)"></span>
  <span class="dot" onclick="currentSlide(2)"></span>
  <span class="dot" onclick="currentSlide(3)"></span>
  <span class="dot" onclick="currentSlide(4)"></span>
  <span class="dot" onclick="currentSlide(5)"></span>
  <span class="dot" onclick="currentSlide(6)"></span>
</div>

<script>
  let slideIndex = 1;
  showSlides(slideIndex);
  
  function plusSlides(n) {
    showSlides(slideIndex += n);
  }
  
  function currentSlide(n) {
    showSlides(slideIndex = n);
  }
  
  function showSlides(n) {
    let i;
    let slides = document.getElementsByClassName("mySlides");
    let dots = document.getElementsByClassName("dot");
    if (n > slides.length) {slideIndex = 1}    
    if (n < 1) {slideIndex = slides.length}
    for (i = 0; i < slides.length; i++) {
      slides[i].style.display = "none";  
    }
    for (i = 0; i < dots.length; i++) {
      dots[i].className = dots[i].className.replace(" active", "");
    }
    slides[slideIndex-1].style.display = "block";  
    dots[slideIndex-1].className += " active";
  }
  </script>
            <h2>Wireframs</h2>
            <p>From here, we compiled the sketches into some initial wireframes. Our primary objective was incentivizing users to complete their profile with a photo and more information. We focused on two avenues to achieve this: 
            </p>
            <ol type="1" class="listItem">
              <li>Adding more calls to action and paths to direct users towards editing their profile </li>
              <li>
                Emphasizing the social connectivity of the platform with the assumption that if you feel like people are actually looking at your profile, you are more likely to care about how it looks. 
              </li>
            </ol >
           
            <p>For our first objective we added more customizable features since we believe that if people want to edit or fill out one feature on their profile they are more likely to fill out more things since they are already on their profile. Some new features we designed to achieve this included: 
            </p>
            <ol type="1" class="listItem">
              <li>“Party anthem” module on the profile page. A fun feature that can help bring people to the edit profile page              </li>
              <li>Rebranding birthday month as horoscope on profile page.This feels less revealing of personal info and is more interesting to know</li>
              <li>Adding complete check mark on profile that can unlock new customization features               </li>
              <li>Including buttons prompting the user to add socials by default when viewing the user’s own profile              </li>
              <li>Add new customization options for profile background (similar to event page)
              </li>
            </ol>
            <img src="assets/wireframe1.1.png" alt="Initial Wireframe">
            <h2>Statistical Analysis</h2>
            <h3>Misclick Rate</h3>
            <p>
                I used a chi-squared test to analyze misclick rate since it relies on categorical (in this case Boolean) data on whether or not the user misclicked.
                <br><br>
                <b>Chi^2 Value:  </b>8.7912
                <br><br>
                <b>P-Value: </b>0.003
                <br><br>
                <b>Misclick Rate A: </b>0.5
                <br><br><b>Misclick Rate B: </b>0.11
                <br><br>
                <b>Analysis: </b> This statistical analysis supported my initial prediction and made me confident that page B had a significantly lower misclick rate. Since the p-value was less than .005, it is statistically significant and allows us to reject the null hypothesis in favor of the alternate hypthesis. Since the calculated misclick rate is 50% for site A and only 11% for site B, suggesting that not only is there a statistical difference between the two site, but that site A has a high misclick rate. The chi-squared value of 8.7912 supports a highest magnitude of deviation which also supports the theory that there is a significant difference between the frequencies on the two sites. <br>All together this allows us to reject the null hypothesis in favor of the alternate one, additionally suggesting that the misclick rate of page A is higher than page B. This indicates that the changes between page A and B led to a reduction in the misclick rate. 
            </p>
            <h3>Time on Page</h3>
            <p>
                I used a one-tailed t-test to analyze the difference between time on site A and site B because time is a continuous variable and my alternative hypothesis was that time on B would be smaller. Therefore, since I wasn't just looking at if the two were different, I was also testing if one was smaller, so the one-tailed test made the most sense.
                <br><br>
                <b>Avg(A):  </b>36,139.458 milliseconds
                <br><br>
                <b>Avg(B): </b>9,164.615 milliseconds
                <br><br>
                <b>Std(A): </b>14,570.9 milliseconds
                <br><br>
                <b>Std(B):  </b>3,176.9 milliseconds
                <br><br>
                <b>T-Score:  </b>-8.8766
                <br><br>
                <b>P-value (B less than A): </b>0.0000000016
                <br><br>
                <b>Analysis: </b> Overall the results of the test support the alternative hypothesis, and my prediction, about page B having a lower time on page. The average value of time on B was less than time on A, and the p-value was extremely low suggesting that there was a statistically significant difference between the time on the two sites. 
                <br>Based on this, we can reject the null hypothesis in favor of the alternative hypothesis that the time spent on page A is greater than page B. 

            </p>
            <h3>Time until First Click</h3>
            <p>
                I used a one-tailed t-test to analyze the difference between time to first click on site A and site B because time is a continuous variable and my alternative hypothesis was that time to first click on B would be smaller. Therefore, since I wasn't just looking at if the two were different, I was also testing if one was smaller, so the one-tailed test made the most sense.
                <br><br>
                <b>Avg(A): </b> 14,476.875 milliseconds
                <br><br>
                <b>Avg(B):  </b>5,675.461 milliseconds
                <br><br>
                <b>Std(A): </b>8,408.1 milliseconds
                <br><br>
                <b>Std(B):  </b>2,927.2 milliseconds
                <br><br>
                <b>T-Score:  </b>-4.863
                <br><br>
                <b>P-value (B less than A): </b>0.000019
                <br><br>
                <b>Analysis: </b> Overall the results of the test support the alternative hypothesis, and my prediction, about page B having a lower time before first click. The average value of time before first click on page A was 14,276 milliseconds, while it was  only 5,675 milliseconds on page B. The P-value was extremely low, significantly below .05, suggesting that there is a statistically significant difference between the time before first click the two sites. <br>Based on this, we can reject the null hypothesis in favor of the alternative hypothesis that the time before first click on page A is significantly greater than page B. 
            </p>
            <h3>Summary Statistics</h3>
            <table>
                <tr>
                  <th></th>
                  <th>Version A</th>
                  <th>Version B</th>
                </tr>
                <tr>
                  <th>Misclick Rate</th>
                  <td>.5</td>
                  <td>.1</td>
                </tr>
                <tr>
                  <th>Avg Time on Page</tj>
                  <td>36,139.46 ms</td>
                  <td>9,164.61 ms</td>
                </tr>
                <tr>
                    <th>Time on Page Std</tj>
                    <td>14,570.9 ms</td>
                    <td>3,176.9 ms</td>
                  </tr>
                <tr>
                  <th>Avg Time to 1st Click</th>
                  <td>14,476.87 ms</td>
                  <td>5,675.46 ms</td> 
                </tr>
                <tr>
                    <th>Time to 1st Click Std</th>
                    <td>8,408.1 ms</td>
                    <td>2,927.2 ms</td> 
                  </tr>
              </table>
              <p>For this project we only collected 24 data points for page A and 23 for page B. In an ideal world we would gain more accurate results using larger quantities of data. 
                <br>
                The large standard deviation for both metrics of page A suggests a significant range in user ease of experience, while the lower range for page B implies a more consistent user experience. The standard deviation also highlights the stark difference between the pages times with page A requiring significantly more time. These findings  apply both to time on page, as well as time to first click. 
              </p>
              <h2>
                Conclusion
              </h2>
              <p>All together the results of these tests allow me to reject all three of my null hypotheses in favor of my alternative hypotheses. Page B consistently outperformed page A in each of the chosen metrics, indicating that the changes applied in page B create a faster and more streamlined user experience, with fewer misclicks. 
            </p>
        </div>
    </body>
</html>
